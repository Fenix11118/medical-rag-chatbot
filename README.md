ğŸ©º Medical RAG Chatbot (LangChain + Pinecone)

This project is a medical question-answering chatbot built using LangChain and Pinecone.
It reads medical PDF files and answers user questions based on those documents.

The chatbot uses Retrieval-Augmented Generation (RAG), which means:

It first searches relevant content from PDFs

Then uses an LLM to generate answers

This helps reduce wrong or made-up answers

ğŸ›  Tech Stack

Python

Flask â€“ backend web framework

LangChain â€“ RAG pipeline

Pinecone â€“ vector database

HuggingFace Embeddings â€“ text embeddings

OpenAI â€“ LLM for answering questions

ğŸ“‚ Project Structure

medical-rag-chatbot/
â”‚
â”œâ”€â”€ app.py                  # Flask app (chat API)
â”œâ”€â”€ store_index.py          # Script to index PDFs into Pinecone
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py           # PDF loading, splitting, embeddings
â”‚   â””â”€â”€ prompt.py           # System prompt
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html           # Chat UI
â”‚
â”œâ”€â”€ Data/                   # Medical PDF files
â”‚   â””â”€â”€ *.pdf
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                    # Environment variables (NOT pushed to GitHub)
â””â”€â”€ README.md


ğŸ”„ How the Project Works

Medical PDFs are loaded from the Data/ folder

Text is split into small chunks

Each chunk is converted into embeddings

Embeddings are stored in Pinecone

User asks a question

Relevant text is retrieved from Pinecone

LLM generates a short, accurate answer

âš™ï¸ Setup Instructions (Step by Step)
1ï¸âƒ£ Clone the repository
git clone https://github.com/Shehjad2019/medical-rag-chatbot.git
cd medical-rag-chatbot

2ï¸âƒ£ Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate   # Mac/Linux
# venv\Scripts\activate    # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ” Pinecone Setup (Important)
Step 1: Create Pinecone Account

Go to ğŸ‘‰ https://www.pinecone.io

Sign up / log in

Go to Dashboard

Step 2: Create Pinecone API Key

Open API Keys section

Copy your API Key

Step 3: Create .env file

In the project root, create a file named .env

PINECONE_API_KEY=your_pinecone_api_key_here
OPENAI_API_KEY=your_openai_api_key_here


ğŸ“Œ Index PDFs into Pinecone

Run this once to store embeddings:

python store_index.py


This will:

Read PDFs

Create embeddings

Upload them to Pinecone

ğŸš€ Run the Application
python app.py


Open browser:

http://localhost:8080


Ask medical questions through the chat UI.

ğŸ§ª Example Questions

What is diabetes?

What are the symptoms of heart disease?

How is hypertension treated?

âš ï¸ Current Limitations

Single-turn questions only (no chat memory)

No PDF upload from UI

Uses similarity-based retrieval only

ğŸ”® Future Improvements

Conversational memory

Source citations

Metadata filtering

Streaming responses

Authentication & rate limiting

ğŸ“Œ Notes

This project is meant for learning and demo purposes

Not intended for real medical diagnosis

Answers depend on uploaded PDFs

ğŸ‘¨â€ğŸ’» Author

Shehjad Patel
Computer Engineering | GenAI & LangChain Enthusiast

â­ If you like this project

Give it a â­ on GitHub ğŸ˜Š


